# app.py
# -*- coding: utf-8 -*-
"""
Streamlit: ê³„ì•½ì„œ ìë™ ì´ìŠˆ ë§ˆí‚¹(ë…ì†Œì¡°í•­) ë¦¬ë·°ì–´ â€” Google Sheet(ë¹„ê³µê°œ, Secrets) ê¸°ë°˜

íŠ¹ì§•
- ë…ì†Œì¡°í•­ ì •ì˜ëŠ” ì „ë¶€ **ë¹„ê³µê°œ Google Sheet**ì—ì„œ ì½ìŒ (ë§í¬/ID UI ë…¸ì¶œ ì—†ìŒ)
- ì‹œíŠ¸ì˜ **A=id, B=title, C=definition** ì»¬ëŸ¼ì„ ì‚¬ìš©
- ê³„ì•½ì„œ ì—…ë¡œë“œ(PDF/DOCX/TXT/MD) â†’ LLMì´ ê° ì´ìŠˆë³„ë¡œ íƒì§€ â†’ ì¢Œì¸¡ í•˜ì´ë¼ì´íŠ¸/ìš°ì¸¡ ìš”ì•½

ì‹¤í–‰ ì¤€ë¹„
  1) requirements.txt (í•„ìˆ˜ íŒ¨í‚¤ì§€)
     streamlit\nopenai\npypdf\npython-docx\ngspread\ngoogle-auth\n
  2) Streamlit Secrets ì„¤ì •
     [í•„ìˆ˜]
       - OPENAI_API_KEY: OpenAI API í‚¤
       - GDRIVE_SERVICE_ACCOUNT_JSON: ì„œë¹„ìŠ¤ê³„ì • JSON ì›ë¬¸ ì „ì²´ (ë¬¸ìì—´)
       - GSHEET_ID: ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID (/d/<ì´ ê°’>/)
     [ì„ íƒ]
       - GSHEET_WORKSHEET: ì›Œí¬ì‹œíŠ¸ ì´ë¦„ (ë¯¸ì…ë ¥ ì‹œ ì²« ë²ˆì§¸ ì‹œíŠ¸)

  3) Google Sheet ê³µìœ  ì„¤ì •
     - í•´ë‹¹ ì‹œíŠ¸ë¥¼ ì„œë¹„ìŠ¤ê³„ì • ì´ë©”ì¼ì— "ë³´ê¸° ê¶Œí•œ"ìœ¼ë¡œ ê³µìœ 

ì‹¤í–‰
  $ streamlit run app.py
"""
from __future__ import annotations
import os
import io
import re
import json
import time
import uuid
import html
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Tuple

import streamlit as st
from pypdf import PdfReader

# DOCX (optional)
try:
    from docx import Document as DocxDocument  # type: ignore
    DOCX_AVAILABLE = True
except Exception:
    DOCX_AVAILABLE = False

# gspread for Google Sheets
try:
    import gspread  # type: ignore
    GSHEETS_AVAILABLE = True
except Exception:
    GSHEETS_AVAILABLE = False

# OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except Exception:
    OPENAI_AVAILABLE = False

# --------------- Constants ---------------
MAX_CHARS = 200_000            # LLM ì•ˆì „ ì ˆë‹¨
DEFAULT_MODEL = "gpt-4o-mini"   # ê¸°ë³¸ ëª¨ë¸ëª… (ì‚¬ì´ë“œë°”ì—ì„œ ìˆ˜ì • ê°€ëŠ¥)

# --------------- Data types ---------------
@dataclass
class Clause:
    idx: int
    title: str
    text: str
    start: int
    end: int

# --------------- File loaders ---------------
def extract_text_pdf(bio: io.BytesIO) -> str:
    reader = PdfReader(bio)
    parts = []
    for p in reader.pages:
        try:
            parts.append(p.extract_text() or "")
        except Exception:
            parts.append("")
    return "\n\n".join(parts)


def extract_text_docx(bio: io.BytesIO) -> str:
    if not DOCX_AVAILABLE:
        return ""
    doc = DocxDocument(bio)
    return "\n".join(p.text for p in doc.paragraphs)


def load_text_from_file(upload) -> str:
    name = upload.name.lower()
    data = upload.read()
    if name.endswith(".pdf"):
        return extract_text_pdf(io.BytesIO(data))
    if name.endswith(".docx") and DOCX_AVAILABLE:
        return extract_text_docx(io.BytesIO(data))
    try:
        return data.decode("utf-8")
    except Exception:
        return data.decode("cp949", errors="ignore")


# --------------- Clause splitter ---------------
def split_into_clauses_kokr(text: str) -> List[Clause]:
    """í•œêµ­/ì˜ë¬¸ ê³„ì•½ì„œì—ì„œ í”í•œ íŒ¨í„´ìœ¼ë¡œ ì¡°í•­ì„ ë¶„í• ."""
    header_pat = re.compile(
        r"(?im)^(\s*(ì œ\s*\d+\s*ì¡°[^\n]*?)\s*$|\s*((?:section|article)\s*\d+[^\n]*?)\s*$|\s*(\d+(?:\.\d+)*\.?\s+[^\n]{0,80})\s*$)"
    )
    headers: List[Tuple[int, str]] = []
    for m in header_pat.finditer(text):
        headers.append((m.start(), m.group(0).strip()))
    if not headers:
        # í—¤ë”ê°€ ì—†ì„ ê²½ìš° ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ ë³´ìˆ˜ ë¶„í• 
        approx = 20
        chunk = max(1000, len(text)//approx)
        pos = 0
        idx = 1
        out: List[Clause] = []
        while pos < len(text):
            end = min(len(text), pos + chunk)
            out.append(Clause(idx, f"Clause {idx}", text[pos:end], pos, end))
            pos = end
            idx += 1
        return out
    headers.append((len(text), "__END__"))
    out: List[Clause] = []
    for i in range(len(headers)-1):
        start = headers[i][0]
        end = headers[i+1][0]
        title = headers[i][1]
        body = text[start:end].strip()
        out.append(Clause(i+1, title, body, start, end))
    return out


# --------------- Google Sheet loader ---------------
# --------------- Google Sheet loader ---------------
def load_issues_from_gsheet_private() -> List[Dict[str, Any]]:
    if not GSHEETS_AVAILABLE:
        raise RuntimeError("gspread íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # âœ… Secrets ì½ê¸° (í…Œì´ë¸” ìš°ì„ , ë¬¸ìì—´ fallback)
    import json as _json
    cfg = None
    if "gcp_sa" in st.secrets:
        cfg = dict(st.secrets["gcp_sa"])  # TOML í…Œì´ë¸”ë¡œ ë„£ì€ ê²½ìš°
    sa_json_str = st.secrets.get("GDRIVE_SERVICE_ACCOUNT_JSON", "").strip()
    if not cfg and sa_json_str:
        cfg = _json.loads(sa_json_str)  # ì˜ˆì „ JSON ë¬¸ìì—´ ë°©ì‹

    # âœ… private_key ì¤„ë°”ê¿ˆ ë³´ì • (JSON ë¬¸ìì—´ ë°©ì‹ì¼ ë•Œ \n â†’ ì‹¤ì œ ê°œí–‰)
    if cfg and isinstance(cfg.get("private_key"), str):
        pk = cfg["private_key"]
        if "\\n" in pk and "\n" not in pk:
            cfg["private_key"] = pk.replace("\\n", "\n")

    sheet_id = st.secrets.get("GSHEET_ID", "").strip()
    sheet_ws = st.secrets.get("GSHEET_WORKSHEET", "").strip() or None

    if not cfg or not sheet_id:
        raise RuntimeError("ì„œë¹„ìŠ¤ê³„ì •/ì‹œíŠ¸ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤. Secretsì˜ [gcp_sa] ë˜ëŠ” GDRIVE_SERVICE_ACCOUNT_JSON, ê·¸ë¦¬ê³  GSHEET_IDë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # âœ… ì„œë¹„ìŠ¤ê³„ì •ìœ¼ë¡œ ì ‘ì†
    gc = gspread.service_account_from_dict(cfg)
    sh = gc.open_by_key(sheet_id)
    ws = sh.worksheet(sheet_ws) if sheet_ws else sh.sheet1

    rows = ws.get_all_values()  # 2D list
    issues: List[Dict[str, Any]] = []
    if not rows:
        return issues

    header = [c.strip().lower() for c in rows[0]] if rows else []
    start_idx = 1 if set(["id", "title", "definition"]).intersection(set(header)) else 0

    for r in rows[start_idx:]:
        if not r or len(r) < 3:
            continue
        a = (r[0] or "").strip()  # id
        b = (r[1] or "").strip()  # title
        c = (r[2] or "").strip()  # definition
        if not (a or b or c):
            continue
        issues.append({
            "id": a or str(uuid.uuid4()),
            "title": b or a or "(untitled)",
            "definition": c,
        })
    return issues



# --------------- LLM provider ---------------
class OpenAILLM:
    def __init__(self, api_key: Optional[str] = None):
        if not OPENAI_AVAILABLE:
            raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. 'pip install openai'")
        self.client = OpenAI(api_key=api_key or st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY"))

    def review(self, *, model: str, issue_id: str, issue_definition: str, full_text: str) -> Dict[str, Any]:
        payload_text = full_text[:MAX_CHARS]
        system = (
            "You are a meticulous contract reviewer. Your SOLE task is to detect ONE specific risk as defined."
            " Return STRICT JSON only."
        )
        user = (
            "ISSUE_DEFINITION: " + issue_definition +
            "\n\nCONTRACT (UTF-8 text):\n" + payload_text +
            "\n\nINSTRUCTIONS:\n"
            "- Look ONLY for the defined issue.\n"
            "- If found, mark found=true and include a concise explanation.\n"
            "- Identify clauses by rough index if possible (e.g., [3,7]).\n"
            "- Output STRICT JSON with this schema and NOTHING else.\n\n"
            "{\n  \"issue_id\": string,\n  \"found\": boolean,\n  \"explanation\": string,\n  \"clause_indices\": number[],\n  \"evidence_quotes\": string[]\n}"
        )
       # app.pyì˜ OpenAILLM.review ë©”ì„œë“œ (ìˆ˜ì •ëœ ë²„ì „)

        resp = self.client.chat.completions.create( # <--- ìˆ˜ì • (1)
            model=model,
            messages=[ # <--- ìˆ˜ì • (2)
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            response_format={"type": "json_object"},
        )
        try:
            text = resp.choices[0].message.content # <--- ìˆ˜ì • (3)
            if not text:
                text = "{}"
        except Exception:
            text = "{}"
        try:
            data = json.loads(text)
        except Exception:
            data = {
                "issue_id": issue_id,
                "found": False,
                "explanation": "Model did not return valid JSON.",
                "clause_indices": [],
                "evidence_quotes": [],
            }
        data.setdefault("issue_id", issue_id)
        data.setdefault("found", False)
        data.setdefault("explanation", "")
        data.setdefault("clause_indices", [])
        data.setdefault("evidence_quotes", [])
        return data


# --------------- UI ---------------
st.set_page_config(page_title="ê³„ì•½ì„œ ì´ìŠˆ ë§ˆí‚¹ ë·°ì–´", layout="wide")
st.title("ğŸ“‘ ê³„ì•½ì„œ ìë™ ì´ìŠˆ ë§ˆí‚¹ & í•˜ì´ë¼ì´íŠ¸ ë·°ì–´")

with st.sidebar:
    st.header("ğŸ”§ ì„¤ì •")
    model = st.text_input("ëª¨ë¸ ì´ë¦„", value=DEFAULT_MODEL)
    api_key = st.text_input("OpenAI API Key (ì„ íƒ: secrets ì‚¬ìš©ì‹œ ë¹„ì›Œë‘ê¸°)", type="password", value=os.getenv("OPENAI_API_KEY", ""))
    st.caption("ë…ì†Œì¡°í•­ ì •ì˜: ë¹„ê³µê°œ Google Sheet(Secrets)ì—ì„œ ìë™ ë¡œë”©")

# ê³„ì•½ì„œ ì—…ë¡œë“œ
uploaded = st.file_uploader("ê³„ì•½ì„œ íŒŒì¼ ì—…ë¡œë“œ (PDF/DOCX/TXT/MD)", type=["pdf","docx","txt","md"]) 
if uploaded is None:
    st.info("ê³„ì•½ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

raw_text = load_text_from_file(uploaded)
if not raw_text.strip():
    st.error("ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìŠ¤ìº” PDFì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤(OCR í•„ìš”).")
    st.stop()

clauses = split_into_clauses_kokr(raw_text)

# Google Sheetì—ì„œ ë…ì†Œì¡°í•­ ë¶ˆëŸ¬ì˜¤ê¸°
try:
    issues_cfg = load_issues_from_gsheet_private()
except Exception as e:
    st.error(f"ë…ì†Œì¡°í•­ ì‹œíŠ¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

if not issues_cfg:
    st.error("ì‹œíŠ¸ì—ì„œ ì½ì€ ë…ì†Œì¡°í•­ì´ ì—†ìŠµë‹ˆë‹¤. A=id, B=title, C=definitionì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

st.caption(f"ë¶ˆëŸ¬ì˜¨ ì´ìŠˆ ì •ì˜: {len(issues_cfg)}ê°œ (Google Sheet from Secrets)")

# LLM í˜¸ì¶œ
llm = OpenAILLM(api_key=api_key)

st.divider()
progress = st.progress(0)
results: List[Dict[str, Any]] = []
for i, issue in enumerate(issues_cfg, start=1):
    issue_id = issue.get("id") or f"issue_{i}"
    title = issue.get("title", issue_id)
    definition = issue.get("definition", "")
    data = llm.review(model=model, issue_id=issue_id, issue_definition=definition, full_text=raw_text)
    data.setdefault("title", title)
    results.append(data)
    progress.progress(int(i/len(issues_cfg)*100))
progress.empty()

found_list = [r for r in results if r.get("found")]

left, right = st.columns([2, 1])

with right:
    st.subheader("ğŸ” íƒì§€ ìš”ì•½")
    st.write(f"ì´ ì´ìŠˆ ìœ í˜•: {len(results)} / ë°œê²¬: {len(found_list)}")
    if found_list:
        for r in found_list:
            with st.expander(f"âœ… {r.get('title', r['issue_id'])}"):
                st.markdown(f"**ì„¤ëª…:** {r.get('explanation','')}")
                idxs = r.get("clause_indices", [])
                if idxs:
                    st.markdown("**ê´€ë ¨ ì¡°í•­ ì¸ë±ìŠ¤:** " + ", ".join(map(str, idxs)))
                quotes = r.get("evidence_quotes", [])
                if quotes:
                    st.markdown("**ê·¼ê±° ì¸ìš©ë¬¸:**")
                    for q in quotes:
                        st.markdown(f"> {q}")
    else:
        st.info("íƒì§€ëœ ë¬¸ì œ ì—†ìŒ(ë˜ëŠ” ëª¨ë¸ì´ íƒì§€í•˜ì§€ ëª»í•¨).")

    st.markdown("---")
    st.download_button(
        "ğŸ“¥ ê²°ê³¼(JSON) ë‹¤ìš´ë¡œë“œ",
        data=json.dumps(results, ensure_ascii=False, indent=2).encode("utf-8"),
        file_name=f"contract_review_results_{int(time.time())}.json",
        mime="application/json",
    )

with left:
    st.subheader("ğŸ“„ ë¬¸ì„œ ë³´ê¸°")
    st.caption("ìš°ì¸¡ ì´ìŠˆ ìš”ì•½ì„ ì°¸ê³ í•˜ì—¬ ê´€ë ¨ ì¡°í•­ì„ í™•ì¸í•˜ì„¸ìš”.")

    # í•˜ì´ë¼ì´íŠ¸: ì´ìŠˆê°€ ë³´ê³ í•œ clause_indicesë¥¼ ë…¸ë€ ë°•ìŠ¤ë¡œ í‘œì‹œ
    highlight_indices = sorted({idx for r in found_list for idx in r.get("clause_indices", []) if isinstance(idx, int)})

    def render_clause_html(c: Clause, highlight: bool) -> str:
        safe = html.escape(c.text)
        bg = "#fffbe6" if highlight else "#f6f7f9"
        border = "1px solid #ffe58f" if highlight else "1px solid #e5e7eb"
        return (
            f"<div style='padding:8px; margin:8px 0; border-radius:12px; background:{bg}; border:{border}'>"
            f"<div style='font-weight:600'>{html.escape(c.title)}</div>"
            f"<div style='white-space:pre-wrap'>{safe}</div>"
            f"</div>"
        )

    html_parts = [render_clause_html(c, c.idx in highlight_indices) for c in clauses]
    st.markdown("\n".join(html_parts), unsafe_allow_html=True)

st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¢Œ/ìš° íŒ¨ë„ì„ ì°¸ê³ í•´ ì£¼ì„¸ìš”.")
