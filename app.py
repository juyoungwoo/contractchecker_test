# app.py
# -*- coding: utf-8 -*-
"""
Streamlit: ê³„ì•½ì„œ ìë™ ì´ìŠˆ ë§ˆí‚¹(ë…ì†Œì¡°í•­) ë¦¬ë·°ì–´ â€” Google Sheet(ë¹„ê³µê°œ, Secrets) ê¸°ë°˜
"""

from __future__ import annotations
import os, io, re, json, time, uuid, html, unicodedata
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from collections import defaultdict

import streamlit as st
from pypdf import PdfReader

# --- ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„í¬íŠ¸ (ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬) ---
# DOCX (optional)
try:
    from docx import Document as DocxDocument
    DOCX_AVAILABLE = True
except Exception:
    DOCX_AVAILABLE = False

# gspread + google-auth
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GSHEETS_AVAILABLE = True
except Exception:
    GSHEETS_AVAILABLE = False

# OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except Exception:
    OPENAI_AVAILABLE = False

# ---------------- Constants ----------------
MAX_CHARS = 200_000
DEFAULT_MODEL = "gpt-4o-mini"

# ---------------- Data types ----------------
@dataclass
class Clause:
    idx: int
    title: str
    text: str

# ---------------- File loaders ----------------
def extract_text_pdf(bio: io.BytesIO) -> str:
    reader = PdfReader(bio)
    return "\n\n".join(p.extract_text() or "" for p in reader.pages)

def extract_text_docx(bio: io.BytesIO) -> str:
    if not DOCX_AVAILABLE: return ""
    doc = DocxDocument(bio)
    return "\n".join(p.text for p in doc.paragraphs)

def load_text_from_file(upload) -> str:
    data = upload.read()
    name = upload.name.lower()
    if name.endswith(".pdf"): return extract_text_pdf(io.BytesIO(data))
    if name.endswith(".docx") and DOCX_AVAILABLE: return extract_text_docx(io.BytesIO(data))
    for enc in ("utf-8", "cp949", "euc-kr"):
        try: return data.decode(enc)
        except Exception: continue
    return data.decode("utf-8", errors="ignore")

# ---------------- Clause splitter (í•µì‹¬ ìˆ˜ì •) ----------------
def split_into_clauses_kokr(text: str) -> List[Clause]:
    """
    'ì œ Oì¡° (ì¡°í•­ëª…)' íŒ¨í„´ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì•½ì„œë¥¼ ë¶„í• í•©ë‹ˆë‹¤.
    ê° ì¡°ì˜ ì œëª©(ê´„í˜¸ í¬í•¨)ì„ ëª…í™•í•˜ê²Œ ì¸ì‹í•˜ê³ , ê·¸ ë‹¤ìŒ ì¡°í•­ ì‹œì‘ ì „ê¹Œì§€ë¥¼ ë³¸ë¬¸ìœ¼ë¡œ ë¬¶ìŠµë‹ˆë‹¤.
    """
    # "ì œ <ìˆ«ì> ì¡° (<ì¡°í•­ëª…>)" íŒ¨í„´ìœ¼ë¡œ ê³„ì•½ì„œ ì¡°í•­ì˜ ì‹œì‘ì ì„ ì°¾ëŠ”ë‹¤.
    # ê·¸ë£¹ 1: ì¡°í•­ ë²ˆí˜¸ (ìˆ«ì)
    # ê·¸ë£¹ 2: ì¡°í•­ ì œëª© (ê´„í˜¸ ì•ˆì˜ ë‚´ìš©)
    clause_pattern = re.compile(r"ì œ\s*(\d+)\s*ì¡°\s*\(([^)]+)\)")
    matches = list(clause_pattern.finditer(text))

    if not matches:
        return []

    clauses = []
    for i, match in enumerate(matches):
        start_pos = match.start()
        # ë‹¤ìŒ ì¡°í•­ì˜ ì‹œì‘ì ì„ í˜„ì¬ ì¡°í•­ì˜ ëì ìœ¼ë¡œ ì„¤ì •
        end_pos = matches[i + 1].start() if i + 1 < len(matches) else len(text)
        
        clause_full_text = text[start_pos:end_pos].strip()
        
        # ì •ê·œì‹ ê·¸ë£¹ì—ì„œ ì¡°í•­ ë²ˆí˜¸ì™€ ì œëª©ì„ ì§ì ‘ ì¶”ì¶œ
        clause_idx = int(match.group(1))
        clause_title_text = match.group(2).strip()
        
        # UIì— í‘œì‹œë  ì „ì²´ ì œëª©ì„ ì¬êµ¬ì„±
        title = f"ì œ{clause_idx}ì¡° ({clause_title_text})"
        
        # ì œëª© ë¶€ë¶„(ë§¤ì¹˜ëœ ì „ì²´ ë¬¸ìì—´)ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ë¥¼ ë³¸ë¬¸ìœ¼ë¡œ ì„¤ì •
        body_only = clause_full_text[len(match.group(0)):].strip()
        
        clauses.append(Clause(idx=clause_idx, title=title, text=body_only))
            
    return clauses

# ---------------- Google Sheet loader ----------------
def _read_secrets_gcp_sa() -> Optional[Dict[str, Any]]:
    import json as _json
    if "gcp_sa" in st.secrets: return dict(st.secrets["gcp_sa"])
    raw = st.secrets.get("GDRIVE_SERVICE_ACCOUNT_JSON", "").strip()
    if raw:
        cfg = _json.loads(raw)
        if "\\n" in cfg.get("private_key",""): cfg["private_key"] = cfg["private_key"].replace("\\n","\n")
        return cfg
    return None

def load_issues_from_gsheet_private() -> List[Dict[str, Any]]:
    if not GSHEETS_AVAILABLE: raise RuntimeError("gspread / google-auth íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    cfg = _read_secrets_gcp_sa()
    if not cfg: st.error("Streamlit Secretsì— GCP ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."); return []
    sheet_id = st.secrets.get("GSHEET_ID", "").strip()
    ws_name  = (st.secrets.get("GSHEET_WORKSHEET", "ë…ì†Œì¡°í•­_ì˜ˆì‹œ")).strip()
    if not sheet_id: st.error("Streamlit Secretsì— Google Sheet IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."); return []
    scopes = ["https://www.googleapis.com/auth/spreadsheets.readonly", "https://www.googleapis.com/auth/drive.readonly"]
    creds = Credentials.from_service_account_info(cfg, scopes=scopes)
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(sheet_id)
    ws = sh.worksheet(ws_name)
    rows = ws.get_all_values()
    issues = []
    if not rows: return issues
    header = [c.strip().lower() for c in rows[0]]
    start_idx = 1 if set(["id","title","definition"]).intersection(header) else 0
    for r in rows[start_idx:]:
        if len(r) < 3: continue
        a,b,c = r[0].strip(), r[1].strip(), r[2].strip()
        if not (a or b or c): continue
        issues.append({"id": a or str(uuid.uuid4()), "title": b or a or "(untitled)", "definition": c})
    return issues

# ---------------- LLM ----------------
class OpenAILLM:
    def __init__(self, api_key: Optional[str]=None):
        if not OPENAI_AVAILABLE: raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        self.api_key = api_key or st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
        if not self.api_key: st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”."); st.stop()
        self.client = OpenAI(api_key=self.api_key)

    def review(self, *, model:str, issue_id:str, issue_title:str, issue_definition:str, full_text:str, clauses: List[Clause]) -> Dict[str, Any]:
        payload_text = full_text[:MAX_CHARS]
        clause_map_str = "\n".join([f"- ì¡°í•­ {c.idx}: \"{c.title}\"" for c in clauses])
        
        system = (
            "You are a meticulous Korean legal assistant **acting on behalf of the 'í•œêµ­ì „ìê¸°ìˆ ì—°êµ¬ì›' (the research institute)**. "
            "Your primary goal is to find **all clauses and paragraphs (í•­)** in the contract that are **disadvantageous or potentially risky for the 'ì—°êµ¬ì›'** in relation to the specified issue. "
            "You must respond in **KOREAN**. Return a **STRICT JSON object**.\n\n"
            
            "ğŸ“Œ **CRITICAL INSTRUCTIONS:**\n"
            "1.  **'ì—°êµ¬ì›'ì˜ ì…ì¥ì—ì„œ ë¶„ì„í•˜ì‹­ì‹œì˜¤:** `CONTRACT`ë¥¼ ê²€í† í•˜ì—¬ 'ì—°êµ¬ì›'ì—ê²Œ ë¶ˆë¦¬í•˜ê±°ë‚˜ ìœ„í—˜í•œ ì¡°í•­ì„ ì‹ë³„í•˜ì‹­ì‹œì˜¤.\n"
            "2.  **í•´ë‹¹ ì´ìŠˆì— ê´€ë ¨ëœ ëª¨ë“  ì¡°í•­ê³¼ í•­ì„ ë¹ ì§ì—†ì´ ì‹ë³„í•˜ì‹­ì‹œì˜¤:** ë‹¨ì¼ ëŒ€í‘œ ì¡°í•­ë§Œì„ ì„ íƒí•˜ì§€ ë§ê³ , ISSUE_DEFINITIONì— ë¶€í•©í•˜ëŠ” **ëª¨ë“  ê´€ë ¨ ì¡°ë¬¸ê³¼ í•­**ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\n"
            "    - ê°™ì€ ì¡°í•­(ì˜ˆ: ì œ12ì¡°) ë‚´ì— ì—¬ëŸ¬ ê°œì˜ í•­(ì˜ˆ: 1í•­, 4í•­ ë“±)ì´ ë¬¸ì œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            "    - ì´ ê²½ìš° `clause_indices`ì—ëŠ” ì¡° ë²ˆí˜¸(ì˜ˆ: 12)ë§Œ í¬í•¨í•˜ê³ , `evidence_quotes` ë° `explanation`ì—ëŠ” ê°ê° í•­ë³„ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n"
            "3.  **ì •í™•í•œ ì¡°í•­ ë²ˆí˜¸ë¥¼ ëª…ì‹œí•˜ì‹­ì‹œì˜¤:** `CLAUSE_LIST`ë¥¼ ì°¸ê³ í•˜ì—¬ ì œ14ì¡° 2í•­ ë“±ìœ¼ë¡œ ì •í™•íˆ ì§€ì •í•˜ì‹­ì‹œì˜¤.\n"
            "4.  **ë¬¸ì œë˜ëŠ” ë¬¸ì¥ì„ ëª…í™•íˆ ì¶”ì¶œí•˜ì‹­ì‹œì˜¤:** ë…ì†Œ ì¡°í•­ì´ ìˆë‹¤ë©´ **ì •í™•í•œ ë¬¸ì¥ ë˜ëŠ” êµ¬ì ˆ**ì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "5.  **ìœ„í—˜ì„± ì„¤ëª…:** í•´ë‹¹ ë¬¸êµ¬ê°€ ì™œ ì—°êµ¬ì›ì—ê²Œ ë¶ˆë¦¬í•œì§€ë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.\n"
            "6.  **ì›ë¬¸ ì¸ìš©:** ì¸ìš©ì€ ë°˜ë“œì‹œ **ì›ë¬¸ ê·¸ëŒ€ë¡œì˜ í•œêµ­ì–´ ë¬¸ì¥**ì´ì–´ì•¼ í•˜ë©°, ì ˆëŒ€ ì˜ì—­í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n"
            "7.  **ê°„ê²°í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ:** ë„ˆë¬´ ê¸´ ì¸ìš©ì€ í”¼í•˜ê³ , í•œ ë¬¸ì¥ ë˜ëŠ” í•œ êµ¬ì ˆì²˜ëŸ¼ ê°„ë‹¨ ëª…í™•í•˜ê²Œ í•˜ì‹­ì‹œì˜¤.\n"
            "8.  **ì¤‘ë³µì„ í”¼í•˜ì‹­ì‹œì˜¤:** ë™ì¼í•œ ìœ„í—˜ì„ ì—¬ëŸ¬ ì¡°í•­ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ì§€ì í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.\n\n"
        
            "ğŸ“Œ **JSON ì¶œë ¥ í˜•ì‹ (STRICT):**\n"
            "ë‹¤ìŒ í˜•ì‹ì„ ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ë”°ë¥´ì‹­ì‹œì˜¤. (í•˜ë‚˜ì˜ JSON ê°ì²´ë§Œ ë°˜í™˜)\n"
            "{\n"
            f"  \"issue_id\": \"{issue_id}\",\n"
            f"  \"issue_title\": \"{issue_title}\",\n"
            "  \"found\": boolean,  // true ë˜ëŠ” false\n"
            "  \"clause_indices\": [ì¡° ë²ˆí˜¸],  // ì˜ˆ: [9, 12]\n"
            "  \"evidence_quotes\": [\"ë¬¸ì œ ë¬¸ì¥ (ì›ë¬¸)\"]  // ë°˜ë“œì‹œ ê³„ì•½ì„œ ì›ë¬¸ê³¼ ì¼ì¹˜í•´ì•¼ í•˜ë©°, í•­ë³„ë¡œ ì—¬ëŸ¬ ë¬¸ì¥ì´ ìˆì„ ìˆ˜ ìˆìŒ\n"
            "  \"explanation\": \"âš ï¸ ì œ[ì¡°ë²ˆí˜¸] [í•­ë²ˆí˜¸]í•­\\n[ë¬¸ì œ ë¬¸ì¥ ì¸ìš©]\\n[ê°„ê²°í•œ ì„¤ëª… (ì—°êµ¬ì› ê´€ì )]\"\n"
            "}\n\n"
        
            "ğŸ“Œ **Explanation í•„ë“œ í˜•ì‹ì€ ë°˜ë“œì‹œ ë‹¤ìŒì„ ë”°ë¥´ì‹­ì‹œì˜¤:**\n"
            "- ì—¬ëŸ¬ í•­ì´ ë¬¸ì œë˜ëŠ” ê²½ìš°, ê° í•­ë§ˆë‹¤ ì•„ë˜ í˜•ì‹ì„ ë°˜ë³µí•˜ì‹­ì‹œì˜¤.\n"
            "- ì²« ì¤„: âš ï¸ ì œ[ì¡°ë²ˆí˜¸] [í•­ë²ˆí˜¸]í•­\\n\n"
            "- ë‘˜ì§¸ ì¤„: ë¬¸ì œ ë¬¸ì¥ ê·¸ëŒ€ë¡œ ì¸ìš©\n"
            "- ì…‹ì§¸ ì¤„: ì™œ ë¬¸ì œê°€ ë˜ëŠ”ì§€ 1~2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…\n\n"
        
            "âœ… ì˜ˆì‹œ:\n"
            "âš ï¸ ì œ12ì¡° 1í•­\n"
            "ë³¸ ê³„ì•½ì€ ì–´ë– í•œ ì‚¬ìœ ë¡œë“  ì‚¬ì „ í†µë³´ ì—†ì´ í•´ì§€í•  ìˆ˜ ìˆë‹¤.\n\n"
            "ì´ëŠ” 'ì—°êµ¬ì›'ì—ê²Œ ë¶ˆë¦¬í•œ ì¼ë°©ì  í•´ì§€ê¶Œì„ ë¶€ì—¬í•˜ë©°, ê³„ì•½ ì•ˆì •ì„±ì„ í•´ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n"
            "âš ï¸ ì œ12ì¡° 4í•­\n"
            "ì—°êµ¬ì›ì€ ì†í•´ ë°œìƒ ì‹œ ë°°ìƒ ì±…ì„ì„ ì „ì ìœ¼ë¡œ ë¶€ë‹´í•œë‹¤.\n\n"
            "ì´ëŠ” ìƒëŒ€ë°© ê³¼ì‹¤ì´ ìˆë”ë¼ë„ ëª¨ë“  ì±…ì„ì„ ì—°êµ¬ì›ì—ê²Œ ì „ê°€í•˜ëŠ” ì¡°í•­ì…ë‹ˆë‹¤.\n\n"
        
            "ğŸ›‘ ì´ í˜•ì‹ì„ ë²—ì–´ë‚  ê²½ìš°, ë¶„ì„ ê²°ê³¼ê°€ ì‚¬ìš©ìì—ê²Œ í‘œì‹œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ ì§€ì¹¨ì„ ë”°ë¥´ì‹­ì‹œì˜¤.\n"
        )



        user = (f"## ISSUE_DEFINITION:\n{issue_definition}\n\n## CLAUSE_LIST:\n{clause_map_str}\n\n## CONTRACT:\n{payload_text}")
        try:
            resp = self.client.chat.completions.create(
                model=model, messages=[{"role":"system","content":system},{"role":"user","content":user}],
                response_format={"type":"json_object"}, temperature=0.0,
            )
            data = json.loads(resp.choices[0].message.content or "{}")
            if data.get("found") and (not data.get("clause_indices") or not data.get("evidence_quotes")):
                data["found"] = False
        except Exception as e:
            st.warning(f"'{issue_title}' ê²€í†  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            data = {"issue_id": issue_id, "found": False, "explanation": "LLM í˜¸ì¶œ ì˜¤ë¥˜", "clause_indices": [], "evidence_quotes": []}
        data.setdefault("issue_id", issue_id); data.setdefault("issue_title", issue_title)
        return data

# ---------------- Highlight helper ----------------
def highlight_text(text: str, quotes: List[str]) -> str:
    """
    ì¸ìš©ë¬¸ì„ **êµµê²Œ** ì²˜ë¦¬ (LLM íŒë‹¨)
    """
    escaped = html.escape(text)
    for quote in quotes:
        quote = quote.strip()
        if not quote: continue
        q_escaped = html.escape(quote)
        if q_escaped in escaped:
            escaped = escaped.replace(q_escaped, f"<b>{q_escaped}</b>")
        else:
            raw_bold = f"<b>{quote}</b>"
            if quote in text:
                escaped = escaped.replace(html.escape(quote), html.escape(raw_bold))
    return escaped.replace("&lt;b&gt;", "<b>").replace("&lt;/b&gt;", "</b>")



# ---------------- UI ----------------
st.set_page_config(page_title="ê³„ì•½ì„œ ë…ì†Œ ì¡°í•­ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ“‘ ê³„ì•½ì„œ ë…ì†Œ ì¡°í•­ ë¶„ì„ê¸°")

with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •(í•„ìš”ì‹œ)")
    model = st.text_input("OpenAI ëª¨ë¸", value=DEFAULT_MODEL)
    api_key = st.text_input("OpenAI API Key", type="password", help="í‚¤ë¥¼ ì…ë ¥í•˜ë©´ Secrets ì„¤ì •ë³´ë‹¤ ìš°ì„  ì ìš©ë©ë‹ˆë‹¤.")
    
uploaded = st.file_uploader("ê³„ì•½ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (PDF/DOCX/TXT/MD)", type=["pdf","docx","txt","md"])
if not uploaded: st.info("ë¶„ì„í•  ê³„ì•½ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."); st.stop()

raw_text = load_text_from_file(uploaded)
if not raw_text.strip(): st.error("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()

clauses = split_into_clauses_kokr(raw_text)

if st.button("ğŸ” ë¶„ì„ ì‹œì‘í•˜ê¸°", type="primary"):
    with st.spinner('AIê°€ ê³„ì•½ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...'):
        if not clauses:
            st.error("ê³„ì•½ì„œì—ì„œ 'ì œ Oì¡°' í˜•ì‹ì˜ ì¡°í•­ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¶„ì„ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); st.stop()
        
        issues_cfg = load_issues_from_gsheet_private()
        if not issues_cfg:
            st.error("Google Sheetì—ì„œ ë¶„ì„í•  ë…ì†Œ ì¡°í•­ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."); st.stop()

        llm = OpenAILLM(api_key=api_key)
        results = [llm.review(
            model=model, issue_id=issue.get("id", str(uuid.uuid4())),
            issue_title=issue.get("title", "Untitled"),
            issue_definition=issue.get("definition", ""), full_text=raw_text,
            clauses=clauses
        ) for issue in issues_cfg]
        
        st.session_state['results'] = results
        st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if 'results' in st.session_state:
    results = st.session_state['results']
    found_issues = [r for r in results if r.get("found")]
    
    st.markdown("---")
    if not found_issues:
        st.success("âœ… ê²€í†  ê²°ê³¼, 'ì—°êµ¬ì›'ì—ê²Œ íŠ¹ë³„íˆ ë¶ˆë¦¬í•œ ë…ì†Œ ì¡°í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
    st.subheader("ğŸ“„ ê²€í† ê°€ í•„ìš”í•œ ì¡°í•­")
    
    issue_clause_indices = sorted(list({idx for issue in found_issues for idx in issue.get("clause_indices", [])}))
    clauses_with_issues = [c for c in clauses if c.idx in issue_clause_indices]

    if not clauses_with_issues and found_issues:
        st.warning("âš ï¸ ë°œê²¬ëœ ì´ìŠˆì™€ ë§¤ì¹­ë˜ëŠ” ì¡°í•­ì„ UIì— í‘œì‹œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. AIê°€ ì¡°í•­ ë²ˆí˜¸ë¥¼ ì œëŒ€ë¡œ ì¸ì‹í•˜ì§€ ëª»í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        for c in clauses_with_issues:
            matched_issues = [r for r in found_issues if c.idx in r.get("clause_indices", [])]
        
            # âœ… ëª¨ë“  evidence_quotes ìˆ˜ì§‘ (í•˜ì´ë¼ì´íŠ¸ ìš©ë„)
            filtered_quotes = [q for issue in matched_issues for q in issue.get("evidence_quotes", [])]
        
            # âœ… ê°•ì¡° í¬í•¨ í…ìŠ¤íŠ¸ ìƒì„±
            highlighted_text = highlight_text(c.text, filtered_quotes)
        
            with st.container(border=True):
                st.markdown(f"### ğŸ“„ {html.escape(c.title)}")
                st.markdown(
                    f"<div style='white-space: pre-wrap; font-size: 1rem; line-height: 1.8'>{highlighted_text}</div>",
                    unsafe_allow_html=True
                )
        
                if matched_issues:
                    st.markdown("---")
                    for issue in matched_issues:
                        st.markdown(issue.get("explanation", ""))
