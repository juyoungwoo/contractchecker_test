# app.py
# -*- coding: utf-8 -*-
"""
Streamlit: ê³„ì•½ì„œ ìë™ ì´ìŠˆ ë§ˆí‚¹(ë…ì†Œì¡°í•­) ë¦¬ë·°ì–´ â€” Google Sheet(ë¹„ê³µê°œ, Secrets) ê¸°ë°˜
"""

from __future__ import annotations
import os, io, re, json, time, uuid, html, unicodedata
from dataclasses import dataclass
from typing import List, Dict, Any, Optional

import streamlit as st
from pypdf import PdfReader

# DOCX (optional)
try:
    from docx import Document as DocxDocument
    DOCX_AVAILABLE = True
except Exception:
    DOCX_AVAILABLE = False

# gspread + google-auth
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GSHEETS_AVAILABLE = True
except Exception:
    GSHEETS_AVAILABLE = False

# OpenAI
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except Exception:
    OPENAI_AVAILABLE = False

# ---------------- Constants ----------------
MAX_CHARS = 200_000
DEFAULT_MODEL = "gpt-4o-mini"

# ---------------- Data types ----------------
@dataclass
class Clause:
    idx: int
    title: str
    text: str
    start: int
    end: int

# ---------------- File loaders ----------------
def extract_text_pdf(bio: io.BytesIO) -> str:
    reader = PdfReader(bio)
    return "\n\n".join(p.extract_text() or "" for p in reader.pages)

def extract_text_docx(bio: io.BytesIO) -> str:
    if not DOCX_AVAILABLE:
        return ""
    doc = DocxDocument(bio)
    return "\n".join(p.text for p in doc.paragraphs)

def load_text_from_file(upload) -> str:
    data = upload.read()
    name = upload.name.lower()
    if name.endswith(".pdf"):
        return extract_text_pdf(io.BytesIO(data))
    if name.endswith(".docx") and DOCX_AVAILABLE:
        return extract_text_docx(io.BytesIO(data))
    for enc in ("utf-8", "cp949", "euc-kr"):
        try:
            return data.decode(enc)
        except Exception:
            continue
    return data.decode("utf-8", errors="ignore")

# ---------------- Clause splitter ----------------
def split_into_clauses_kokr(text: str) -> List[Clause]:
    """
    í•œêµ­ ê³„ì•½ì„œë¥¼ 'ì œ n ì¡°' ë‹¨ìœ„ë¡œ ë¶„í• .
    ë³¸ë¬¸ ë‚´ 'ì œnì¡°' ì°¸ì¡°ëŠ” ë¬´ì‹œí•˜ê³ , ì¤„ ì‹œì‘(^)ì—ì„œë§Œ ë§¤ì¹­.
    """
    # ì¤„ ì‹œì‘ì—ì„œë§Œ 'ì œ n ì¡°' ì¡ê¸° (ì˜ˆ: ì œ 1 ì¡°, ì œ1ì¡°, ì œ12ì¡°)
    header_pat = re.compile(r"(?m)^(ì œ\s*\d+\s*ì¡°[^\n]*)")

    headers = [(m.start(), m.group(0).strip()) for m in header_pat.finditer(text)]
    if not headers:
        # fallback: í†µì§¸ë¡œ ë°˜í™˜
        return [Clause(1, "ì „ì²´", text.strip(), 0, len(text))]

    headers.append((len(text), "__END__"))

    clauses: List[Clause] = []
    for i in range(len(headers) - 1):
        start, title = headers[i]
        end = headers[i + 1][0]
        body = text[start:end].strip()
        clauses.append(Clause(i + 1, title, body, start, end))

    return clauses


# ---------------- Google Sheet loader ----------------
def _normalize(s: str) -> str:
    return unicodedata.normalize("NFC", (s or "").strip()).lower()

def _open_worksheet_robust(sh, target_name: Optional[str]):
    if not target_name:
        return sh.sheet1
    try:
        return sh.worksheet(target_name)
    except Exception:
        pass
    for ws in sh.worksheets():
        if _normalize(ws.title) == _normalize(target_name):
            return ws
    return sh.sheet1

def _read_secrets_gcp_sa() -> Optional[Dict[str, Any]]:
    import json as _json
    # st.secretsì— gcp_sa í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
    if "gcp_sa" in st.secrets:
        return dict(st.secrets["gcp_sa"])
    # í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” st.secretsì—ì„œ GDRIVE_SERVICE_ACCOUNT_JSON ê°’ì„ ì½ì–´ì˜´
    raw = st.secrets.get("GDRIVE_SERVICE_ACCOUNT_JSON", "").strip()
    if raw:
        try:
            cfg = _json.loads(raw)
            # JSON ë‚´ private_keyì˜ \nì„ ì‹¤ì œ ê°œí–‰ ë¬¸ìë¡œ ë³€ê²½
            if "\\n" in cfg.get("private_key","") and "\n" not in cfg["private_key"]:
                cfg["private_key"] = cfg["private_key"].replace("\\n","\n")
            return cfg
        except _json.JSONDecodeError:
            st.error("GDRIVE_SERVICE_ACCOUNT_JSONì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None
    return None

def load_issues_from_gsheet_private() -> List[Dict[str, Any]]:
    if not GSHEETS_AVAILABLE:
        raise RuntimeError("gspread / google-auth íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # GCP ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´ ì½ê¸°
    cfg = _read_secrets_gcp_sa()
    if not cfg:
        st.error("Streamlit Secretsì— GCP ì„œë¹„ìŠ¤ ê³„ì • ì •ë³´(gcp_sa ë˜ëŠ” GDRIVE_SERVICE_ACCOUNT_JSON)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.info("ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ Streamlit ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”: https://docs.streamlit.io/deploy/streamlit-community-cloud/deploy-your-app/secrets-management")
        return []

    # Google Sheet ID ë° ì›Œí¬ì‹œíŠ¸ ì´ë¦„ ì½ê¸°
    sheet_id = st.secrets.get("GSHEET_ID", "").strip()
    ws_name  = (st.secrets.get("GSHEET_WORKSHEET", "ë…ì†Œì¡°í•­_ì˜ˆì‹œ")).strip() # ê¸°ë³¸ ì›Œí¬ì‹œíŠ¸ ì´ë¦„ ì„¤ì •

    if not sheet_id:
        st.error("Streamlit Secretsì— Google Sheet ID (GSHEET_ID)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return []

    # Google API ì ‘ê·¼ ê¶Œí•œ ì„¤ì •
    scopes = [
        "https://www.googleapis.com/auth/spreadsheets.readonly",
        "https://www.googleapis.com/auth/drive.readonly",
    ]
    
    try:
        creds = Credentials.from_service_account_info(cfg, scopes=scopes)
        gc = gspread.authorize(creds)

        sh = gc.open_by_key(sheet_id)
        ws = _open_worksheet_robust(sh, ws_name)
        rows = ws.get_all_values()
    except gspread.exceptions.SpreadsheetNotFound:
        st.error(f"Google Sheetë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. IDê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”: {sheet_id}")
        return []
    except Exception as e:
        st.error(f"Google Sheet ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return []


    issues = []
    if not rows: return issues
    # í—¤ë” ìœ ë¬´ë¥¼ íŒë‹¨í•˜ì—¬ ë°ì´í„° ì‹œì‘ ì¸ë±ìŠ¤ ê²°ì •
    header = [c.strip().lower() for c in rows[0]]
    start_idx = 1 if set(["id","title","definition"]).intersection(header) else 0

    # ì‹œíŠ¸ì˜ ê° í–‰ì„ ì½ì–´ ë…ì†Œ ì¡°í•­ ëª©ë¡ ìƒì„±
    for r in rows[start_idx:]:
        if len(r) < 3: continue
        # ê° ì…€ì˜ ê°’ì—ì„œ ê³µë°± ì œê±°
        a, b, c = r[0].strip(), r[1].strip(), r[2].strip()
        if not (a or b or c): continue
        issues.append({"id": a or str(uuid.uuid4()), "title": b or a or "(untitled)", "definition": c})
    return issues

# ---------------- LLM ----------------
class OpenAILLM:
    def __init__(self, api_key: Optional[str]=None):
        if not OPENAI_AVAILABLE:
            raise RuntimeError("openai íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        # API í‚¤ê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ ìš”ì²­
        self.api_key = api_key or st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            st.error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        self.client = OpenAI(api_key=self.api_key)

    def review(self, *, model:str, issue_id:str, issue_definition:str, full_text:str) -> Dict[str, Any]:
        payload_text = full_text[:MAX_CHARS]
        system = (
            "You are a meticulous contract reviewer. "
            "Detect ONLY the given risk as defined. "
            "Return STRICT JSON with exactly this schema:\n"
            "{\n"
            "  \"issue_id\": string,\n"
            "  \"found\": boolean,\n"
            "  \"explanation\": string,\n"
            "  \"clause_indices\": number[],\n"
            "  \"evidence_quotes\": string[]\n"
            "}\n"
            "- 'clause_indices' = which clause numbers (approx) contain the issue.\n"
            "- 'evidence_quotes' = exact text snippets from the contract that triggered detection."
        )
        user = (
            f"ISSUE_DEFINITION:\n{issue_definition}\n\n"
            f"CONTRACT:\n{payload_text}"
        )
    
        try:
            resp = self.client.chat.completions.create(
                model=model,
                messages=[{"role":"system","content":system},{"role":"user","content":user}],
                response_format={"type":"json_object"},
                temperature=0,
            )
            text = (resp.choices[0].message.content or "{}")
            data = json.loads(text)
        except Exception as e:
            # API í˜¸ì¶œ ì‹¤íŒ¨ ë˜ëŠ” JSON íŒŒì‹± ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            st.warning(f"'{issue_id}' ê²€í†  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            data = {
                "issue_id": issue_id,
                "found": False,
                "explanation": f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}",
                "clause_indices": [],
                "evidence_quotes": [],
            }
        
        # ê¸°ë³¸ê°’ ì„¤ì •
        data.setdefault("issue_id", issue_id)
        return data


# ---------------- Highlight helper ----------------
def highlight_text(text: str, quotes: List[str]) -> str:
    """evidence_quotesì— ë‚˜ì˜¨ êµ¬ì ˆì„ <mark> íƒœê·¸ë¡œ ê°ì‹¸ê¸°"""
    safe = html.escape(text)
    for q in quotes:
        q = q.strip()
        if not q:
            continue
        # ì •ê·œí‘œí˜„ì‹ì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        q_esc = re.escape(html.escape(q))
        safe = re.sub(q_esc, f"<mark>{html.escape(q)}</mark>", safe, flags=re.IGNORECASE)
    return safe

# ---------------- UI ----------------
st.set_page_config(page_title="ê³„ì•½ì„œ ì´ìŠˆ ë§ˆí‚¹ ë·°ì–´", layout="wide")
st.title("ğŸ“‘ ê³„ì•½ì„œ ìë™ ì´ìŠˆ ë§ˆí‚¹ & í•˜ì´ë¼ì´íŠ¸ ë·°ì–´")

# --- ì‚¬ì´ë“œë°” ì„¤ì • ---
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    # ëª¨ë¸ ì´ë¦„ ì…ë ¥ í•„ë“œ
    model = st.text_input("ëª¨ë¸ ì´ë¦„", value=DEFAULT_MODEL)
    # OpenAI API í‚¤ ì…ë ¥ í•„ë“œ (ë¹„ë°€ë²ˆí˜¸ íƒ€ì…ìœ¼ë¡œ)
    api_key_input = st.text_input("OpenAI API Key", type="password", help="ì—¬ê¸°ì— í‚¤ë¥¼ ì…ë ¥í•˜ë©´ í™˜ê²½ë³€ìˆ˜ë‚˜ Secrets ì„¤ì •ë³´ë‹¤ ìš°ì„  ì ìš©ë©ë‹ˆë‹¤.")
    
    # API í‚¤ ìš°ì„ ìˆœìœ„: 1. UI ì…ë ¥ 2. Streamlit Secrets 3. í™˜ê²½ë³€ìˆ˜
    api_key = api_key_input or st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

# --- ê³„ì•½ì„œ íŒŒì¼ ì—…ë¡œë“œ ---
uploaded = st.file_uploader("ê³„ì•½ì„œ ì—…ë¡œë“œ (PDF/DOCX/TXT/MD)", type=["pdf","docx","txt","md"])
if not uploaded:
    st.info("ë¶„ì„í•  ê³„ì•½ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

# íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
raw_text = load_text_from_file(uploaded)
if not raw_text.strip():
    st.error("íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

# í…ìŠ¤íŠ¸ë¥¼ ì¡°í•­ë³„ë¡œ ë¶„ë¦¬
clauses = split_into_clauses_kokr(raw_text)
st.success(f"ì´ {len(clauses)}ê°œì˜ ì¡°í•­ì„ ì¸ì‹í–ˆìŠµë‹ˆë‹¤.")

# --- ë¶„ì„ ì‹œì‘ ë²„íŠ¼ ---
if st.button("ğŸ” ë¶„ì„ ì‹œì‘í•˜ê¸°"):
    try:
        # Google Sheetì—ì„œ ë…ì†Œ ì¡°í•­ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
        issues_cfg = load_issues_from_gsheet_private()
    except Exception as e:
        st.exception(e)
        st.stop()

    if not issues_cfg:
        st.error("Google Sheetì—ì„œ ë…ì†Œ ì¡°í•­ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    llm = OpenAILLM(api_key=api_key)
    
    # ë¶„ì„ ì§„í–‰ ìƒí™© í‘œì‹œ
    progress_bar = st.progress(0, text="ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    results = []
    total_issues = len(issues_cfg)
    
    # ê° ë…ì†Œ ì¡°í•­ì— ëŒ€í•´ LLM ë¦¬ë·° ìˆ˜í–‰
    for i, issue in enumerate(issues_cfg, 1):
        progress_text = f"'{issue.get('title', '')}' ì¡°í•­ ê²€í†  ì¤‘... ({i}/{total_issues})"
        progress_bar.progress(int(i / total_issues * 100), text=progress_text)
        
        data = llm.review(
            model=model,
            issue_id=issue.get("id", f"issue_{i}"),
            issue_definition=issue.get("definition", ""),
            full_text=raw_text
        )
        data["title"] = issue.get("title", "")
        results.append(data)
    
    progress_bar.empty()
    st.success("ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    # --- ë¶„ì„ ê²°ê³¼ í‘œì‹œ ---
    found_issues = [r for r in results if r.get("found")]

    if not found_issues:
        st.info("ê²€í†  ê²°ê³¼, ê³„ì•½ì„œì—ì„œ íŠ¹ë³„í•œ ë…ì†Œ ì¡°í•­ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        st.subheader(f"ğŸš¨ ì´ {len(found_issues)}ê°œì˜ ì ì¬ì  ì´ìŠˆ ë°œê²¬")

    st.subheader("ğŸ“„ ë¬¸ì„œ ë³´ê¸° (ë³¸ë¬¸ + ê²€í†  ì˜ê²¬)")

    for c in clauses:
        # í˜„ì¬ ì¡°í•­ê³¼ ê´€ë ¨ëœ ì´ìŠˆ í•„í„°ë§
        matched_issues = [r for r in results if c.idx in r.get("clause_indices", [])]
        
        # ê´€ë ¨ëœ ëª¨ë“  ì¸ìš©êµ¬(ì¦ê±° ë¬¸ì¥) ìˆ˜ì§‘
        all_quotes = [q for issue in matched_issues for q in issue.get("evidence_quotes", [])]
        
        # ì¸ìš©êµ¬ë¥¼ ë³¸ë¬¸ì—ì„œ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬
        highlighted_text = highlight_text(c.text, all_quotes)

        # UIë¥¼ 2ë‹¨ìœ¼ë¡œ ë¶„ë¦¬ (ì™¼ìª½: ê³„ì•½ì„œ ë‚´ìš©, ì˜¤ë¥¸ìª½: ê²€í†  ì˜ê²¬)
        col1, col2 = st.columns([3, 2], gap="large")
        
        with col1:
            # ê³„ì•½ì„œ ì¡°í•­ í‘œì‹œ
            st.markdown(
                f"<div style='padding: 1rem; margin: 0.5rem 0; border-radius: 8px; background-color: #f8f9fa; border: 1px solid #e9ecef;'>"
                f"<h4>{html.escape(c.title)}</h4>"
                f"<div style='white-space: pre-wrap; line-height: 1.6;'>{highlighted_text}</div>"
                f"</div>",
                unsafe_allow_html=True
            )
        
        with col2:
            if matched_issues:
                # ë°œê²¬ëœ ì´ìŠˆ(ë©”ëª¨) í‘œì‹œ
                for issue in matched_issues:
                    st.markdown(
                        f"<div style='padding: 0.8rem; margin: 0.5rem 0; border-left: 5px solid #ff4b4b; background-color: #fff0f0; border-radius: 6px;'>"
                        f"<p style='margin: 0;'><strong>âš ï¸ {html.escape(issue.get('title', issue['issue_id']))}</strong></p>"
                        f"<p style='margin: 0.5rem 0 0 0;'>{html.escape(issue.get('explanation', ''))}</p>"
                        f"</div>", 
                        unsafe_allow_html=True
                    )
            else:
                # ì´ìŠˆê°€ ì—†ëŠ” ê²½ìš°, ë¹ˆ ê³µê°„ì„ ìœ ì§€í•˜ì—¬ UI ì •ë ¬ ë§ì¶¤
                st.markdown("<div style='height: 1rem;'></div>", unsafe_allow_html=True)


    # --- ê²°ê³¼ ë‹¤ìš´ë¡œë“œ ---
    st.download_button(
        label="ğŸ“¥ JSON ê²°ê³¼ ë‹¤ìš´ë¡œë“œ",
        data=json.dumps(results, ensure_ascii=False, indent=2).encode('utf-8'),
        file_name=f"review_{int(time.time())}.json",
        mime="application/json"
    )
